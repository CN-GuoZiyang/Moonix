# 4.2 内核初始映射

----

# 移动内核

现在的内核运行在起始地址为 `0x80200000` 的物理内存空间上。我们的需求是，让内核运行在起始地址为 `0xffffffff80200000` 的虚拟内存空间。这意味着我们需要将内核的所有地址向高地址空间平移，这是一种线性映射的方式，映射的偏移量为 `0xffffffff00000000`。

我们通过修改链接脚本的一些参数来达成这个目的：

```c
/* 目标架构 */
OUTPUT_ARCH(riscv)

/* 执行入口 */
ENTRY(_start)

/* 数据存放起始虚拟地址 */
BASE_ADDRESS = 0xffffffff80200000;

SECTIONS
{
    /* . 表示当前地址（location counter） */
    . = BASE_ADDRESS;

    /* start 符号表示全部的开始位置 */
    kernel_start = .;

    . = ALIGN(4K);
    text_start = .;

    /* .text 字段 */
    .text : {
        /* 把 entry 函数放在最前面 */
        *(.text.entry)
        /* 要链接的文件的 .text 字段集中放在这里 */
        *(.text .text.*)
    }

    . = ALIGN(4K);
    rodata_start = .;

    /* .rodata 字段 */
    .rodata : {
        /* 要链接的文件的 .rodata 字段集中放在这里 */
        *(.rodata .rodata.*)
    }

    . = ALIGN(4K);
    data_start = .;

    /* .data 字段 */
    .data : {
        *(.data .data.*)
    }

    . = ALIGN(4K);
    bss_start = .;

    /* .bss 字段 */
    .bss : {
        *(.sbss .bss .bss.*)
    }

    /* 内核结束地址 */
    . = ALIGN(4K);
    kernel_end = .;
}
```

主要的修改就是将 BASE_ADDRESS 改为了虚拟地址，并且将每个段都和 4K 字节对齐，也就是和页边界对齐。这样的好处是，不会有一个页同时包含两个不同段的内容，每个页都只包含唯一的一个段，便于设置这个页的权限。

我们可以在代码中保存一些常量，以便编程使用。

```c
// kernel/consts.h

// 内核起始的虚拟地址
#define KERNEL_BEGIN_VADDR  0xffffffff80200000

// 内核地址线性映射偏移
#define KERNEL_MAP_OFFSET   0xffffffff00000000
```

在我们设置完成链接脚本后，再次编译启动前，我们来思考一下，当 OpenSBI 运行结束后，跳转到物理地址 0x80200000 时，内核运行的状况：

- PC 指向 0x80200000，CPU 此时无论是取址还是访存都是直接访问物理内存的
- 内核被放置在 0x80200000 开头的物理地址空间，但是内核觉得自己是运行在 0xffffffff80200000 开头的地址空间上

这就意味着，内核所有的符号都是高地址符号。进入内核前的那一段汇编运行不会出错，但是在跳转到 `main` 时就出现问题了，`main` 是一个高地址空间符号，CPU 依照此时的模式却会把它当成一个物理地址来正常地寻址，那自然是找不到的。

所以在执行跳转之前，我们需要设置一番。具体的，就是设置一个页表空间，并且将其基地址物理页号写入 satp 寄存器，并设置 Sv39 模式。我们可以利用大页机制，先设立一个简单的页表。

> [!TIP|label:Note|]
> **大页机制**
>
> Sv39 机制采用三级页表，其中只有一级页表的页表项直接指向物理页，二级和三级页表的页表项都指向下一级页表。
>
> 事实上，我们可以设置二级页表项的 X、W 和 R 位不全为 0，来让其也指向一段物理地址空间。一个一级页表项可以表示一个虚拟页号，一个二级页表项可以表示 9 位一级页表项，即可表示 512 个页，即 2M 字节的虚拟内存，同理一个三级页表项可以表示 1G 字节的空间。

# 设立页表

我们在内核初始化的过程中就需要设置好映射机制。

```
# kernel/entry.asm

.section .text.entry
    .globl _start
    # 设置了 sp 并跳转到 main
_start:
    # 计算 bootpagetable 的物理页号
    lui t0, %hi(bootpagetable)
    li t1, 0xffffffff00000000
    sub t0, t0, t1
    srli t0, t0, 12
    # 设置使用 SV39
    li t1, (8 << 60)
    or t0, t0, t1
    # 写入 satp 并刷新 TLB
    csrw satp, t0
    sfence.vma

    # 加载栈地址
    lui sp, %hi(bootstacktop)
    addi sp, sp, %lo(bootstacktop)

    # 跳转到 main
    lui t0, %hi(main)
    addi t0, t0, %lo(main)
    jr t0

    .section .bss.stack
    .align 12
    # 以下 4096 × 16 字节的空间作为 OS 的启动栈
    .global bootstack
bootstack:
    .space 4096 * 16
    .global bootstacktop
bootstacktop:

    # 初始内核映射所用的页表
    .section .data
    .align 12
bootpagetable:
    .quad 0
    .quad 0
    # 第 2 项：0x80000000 -> 0x80000000，0xcf 表示 VRWXAD 均为 1
    .quad (0x80000 << 10) | 0xcf
    .zero 507 * 8
    # 第 510 项：0xffffffff80000000 -> 0x80000000，0xcf 表示 VRWXAD 均为 1
    .quad (0x80000 << 10) | 0xcf
    .quad 0
```

更具体的，我们只做了以下几件事：

1. 计算页表的物理页号
2. 将页表的物理页号写入 satp
3. 设置 satp 为 Sv39 模式
4. 刷新 TLB
5. 计算栈地址并写入 sp
6. 计算 main 的地址并跳转

> [!TIP|label:Note|]
> **TLB**
>
> CPU 进行地址翻译时，每次都需要在内存中查找页表，但物理内存的速度比 CPU 的速度慢得多。譬如一个取指的过程，原本就只需要一次访存，使用地址翻译后竟需要四次访存才能将指令加载到寄存器，这样无疑大大拖慢的运行效率。
>
> CPU 为了加速地址翻译的过程，在内部设立了一个元器件**快表（TLB）**，来缓存最近访问过的页表项。由于局部性原理，当我们需要查询一个映射时，会有很大可能这个映射在近期被查询过，保存在 TLB 中，所以我们可以先到 TLB 里面去查一下，如果有的话我们就可以直接完成映射，而不用访问那么多次内存了。
> 
> 但如果我们修改了 satp 寄存器，切换到了一个不同的页表，TLB并不会自动刷新，这时 TLB 中缓存的页表项仍然是旧页表的页表项，再次访存就可能出现错误。这个时候我们就需要使用指令 `sfence.vma` 来手动刷新 TLB。

这里我们使用的就是大页机制来设立页表，页表的第 510 项将以 0xffffffff80000000 开头的 1G 字节虚拟地址空间映射到了以 0x80000000 开头的物理地址空间，同时 0xcf 设置了该页表项的属性。

我们注意到，在页表中还有一项 0x80000000 到 0x80000000 的映射，这是因为从刷新 TLB 后，内核开始运行在高地址空间，取指访存等都按照 0xffffffff80000000 到 0x80000000 来进行，但是此时 sp 指针的值未被刷新，其中仍然是低地址，取指时就会发生错误。这一条映射就是临时为这段代码的取址准备的。而在跳转之后，跳转指令会将 sp 设置为 `main` 符号的地址，而这个地址是高地址，就不会产生问题了。

重新运行一下，我们的输出对比上一章不会有变化，这说明内核已经安全地运行在了虚拟地址空间了。